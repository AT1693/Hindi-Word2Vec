{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Skip-Gram.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QnYY0GT56Ztr"
      },
      "source": [
        "### 1. Important Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E9reVI456bDM",
        "outputId": "217a8271-83f6-45c1-e9ac-319b1c59321a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Mount Google Drive on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root = '/content/drive/My Drive/HindiDataset'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JCNwBeoa6Ztu",
        "outputId": "a4de9f61-8935-478b-c17d-ebfe26613243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "!pip install tensorflow==1.4.0\n",
        "import collections\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import string\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "from __future__ import print_function\n",
        "from matplotlib import pylab\n",
        "from matplotlib.font_manager import FontProperties\n",
        "from six.moves import range\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "%matplotlib inline\n",
        "hindi_font = FontProperties(fname=os.path.join(root, 'Nirmala.ttf'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (1.1.10)\n",
            "Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (1.18.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (1.12.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (3.2.1)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (1.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (1.0.1)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (0.9999999)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.4.0) (46.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qV5BmraR0C16"
      },
      "source": [
        "### 2. Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fPYd0Xpz6Zty",
        "colab": {}
      },
      "source": [
        "def clean_text(sentence, language):\n",
        "    \"\"\"\n",
        "        Input: String, String\n",
        "        Output: String\n",
        "        Takes in text as string. Returns text cleaned for NMT purposes.\n",
        "    \"\"\"\n",
        "    if language == None:\n",
        "        print(\"Please enter which language.\")\n",
        "        return None\n",
        "        \n",
        "    exclude = set(string.punctuation)\n",
        "    remove_digits = str.maketrans('', '', string.digits)\n",
        "        \n",
        "    if language == 'en':\n",
        "        sentence = sentence.lower()\n",
        "        sentence = ''.join(ch for ch in sentence if ch not in exclude)\n",
        "        sentence = sentence.translate(remove_digits)\n",
        "        sentence = sentence.strip()\n",
        "        sentence = re.sub(\" +\", \" \", sentence)\n",
        "        return sentence\n",
        "    \n",
        "    elif language == 'hi':\n",
        "        sentence = sentence.lower()\n",
        "        sentence = ''.join(ch for ch in sentence if ch not in exclude)\n",
        "\n",
        "        sent_temp = ''\n",
        "        for c in sentence:\n",
        "            if c == ' ':\n",
        "                sent_temp += c\n",
        "            elif ord(u'\\u0900') <= ord(c) <= ord(u'\\u097F'):\n",
        "                sent_temp += c\n",
        "        sentence = sent_temp\n",
        "      \n",
        "        sentence = re.sub('[a-z]', '', sentence)\n",
        "        sentence = re.sub('[०१२३४५६७८९।]', '', sentence)\n",
        "        sentence = sentence.translate(remove_digits)\n",
        "        sentence = sentence.strip()\n",
        "        sentence = re.sub(\" +\", \" \", sentence)\n",
        "        return sentence\n",
        "    \n",
        "    elif language == 'ma':\n",
        "        sentence = sentence.lower()\n",
        "        sentence = ''.join(ch for ch in sentence if ch not in exclude)\n",
        "        sentence = re.sub('[a-z]', '', sentence)\n",
        "        sentence = re.sub('[०१२३४५६७८९।]', '', sentence)\n",
        "        sentence = sentence.translate(remove_digits)\n",
        "        sentence = sentence.strip()\n",
        "        sentence = re.sub(\" +\", \" \", sentence)\n",
        "        return sentence\n",
        "    \n",
        "    else:\n",
        "        print(\"Language not found\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5dq-afCb6Zt0",
        "outputId": "de913a6f-9ad3-49bf-9bbc-e6f559947a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def read_data(filename, number_of_lines):\n",
        "    data = list()\n",
        "    \n",
        "    with open(os.path.join(root, filename)) as f:\n",
        "        for i in  range(number_of_lines):\n",
        "            data.extend(clean_text(tf.compat.as_str(f.readline()).strip(), 'hi').split(' '))\n",
        "    return data\n",
        "\n",
        "words = read_data('result.txt', 5000000)\n",
        "print(\"Data size %d\" % len(words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size 6647499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y383QUVA6Zt7",
        "outputId": "3487971f-5944-456d-ea38-35bbc8bde453",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "vocabulary_size = int(len(set(words)) // 1.2)\n",
        "\n",
        "def build_dataset(words):\n",
        "    count = [['UNK', -1]]\n",
        "    count.extend(collections.Counter(words).most_common(vocabulary_size-1))\n",
        "    dictionary = dict()\n",
        "    \n",
        "    for word, _ in count:\n",
        "        dictionary[word] = len(dictionary)\n",
        "    \n",
        "    data = list()\n",
        "    unk_count = 0\n",
        "    \n",
        "    for word in words:\n",
        "        if word in dictionary:\n",
        "            index = dictionary[word]\n",
        "        else:\n",
        "            index = 0\n",
        "            unk_count += 1\n",
        "        data.append(index)\n",
        "    \n",
        "    count[0][1] = unk_count\n",
        "    \n",
        "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
        "    return data, count, dictionary, reverse_dictionary\n",
        "\n",
        "data, count, dictionary, reverse_dictionary = build_dataset(words)\n",
        "print(\"Vocabulary size\", vocabulary_size)\n",
        "print(\"Most common words (+UNK)\", count[:5])\n",
        "print(\"Sample data\", data[:10])\n",
        "del words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size 29369\n",
            "Most common words (+UNK) [['UNK', 5875], ('', 4999961), ('है', 69581), ('के', 56900), ('में', 40329)]\n",
            "Sample data [1054, 4396, 42, 19, 147, 751, 685, 74, 28, 182]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNXkilWY6ZuA",
        "outputId": "5f9a890e-e089-45df-b43f-bcbbc1083193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "data_index = 0\n",
        "\n",
        "def generate_batch(batch_size, num_skips, skip_window):\n",
        "    global data_index\n",
        "    assert batch_size % num_skips == 0\n",
        "    assert num_skips <= 2 * skip_window\n",
        "    \n",
        "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
        "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
        "    span = 2 * skip_window + 1\n",
        "    buffer = collections.deque(maxlen=span)\n",
        "    \n",
        "    for _ in range(span):\n",
        "        buffer.append(data[data_index])\n",
        "        data_index = (data_index + 1) % len(data)\n",
        "    \n",
        "    for i in range(batch_size // num_skips):\n",
        "        target = skip_window\n",
        "        targets_to_avoid = [skip_window]\n",
        "        \n",
        "        for j in range(num_skips):\n",
        "            while target in targets_to_avoid:\n",
        "                target = random.randint(0, span-1)\n",
        "            targets_to_avoid.append(target)\n",
        "            batch[i * num_skips + j] = buffer[skip_window]\n",
        "            labels[i * num_skips + j, 0] = buffer[target]\n",
        "        buffer.append(data[data_index])\n",
        "        data_index = (data_index + 1) % len(data)\n",
        "    return batch, labels\n",
        "\n",
        "print(\"Data:\", [reverse_dictionary[di] for di in data[:8]])\n",
        "\n",
        "for num_skips, skip_window in [(2, 1), (4, 2)]:\n",
        "    data_index = 0\n",
        "    batch, labels = generate_batch(batch_size=8, num_skips=num_skips, skip_window=skip_window)\n",
        "    print(\"\\nwith num_skips = %d and skip_window = %d:\" % (num_skips, skip_window))\n",
        "    print(\"    batch:\", [reverse_dictionary[bi] for bi in batch])\n",
        "    print(\"    labels:\", [reverse_dictionary[di] for di in labels.reshape(8)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: ['आदरणीय', 'अध्यक्षा', 'जी', 'मैं', 'आपका', 'आभार', 'व्यक्त', 'करता']\n",
            "\n",
            "with num_skips = 2 and skip_window = 1:\n",
            "    batch: ['अध्यक्षा', 'अध्यक्षा', 'जी', 'जी', 'मैं', 'मैं', 'आपका', 'आपका']\n",
            "    labels: ['जी', 'आदरणीय', 'अध्यक्षा', 'मैं', 'आपका', 'जी', 'आभार', 'मैं']\n",
            "\n",
            "with num_skips = 4 and skip_window = 2:\n",
            "    batch: ['जी', 'जी', 'जी', 'जी', 'मैं', 'मैं', 'मैं', 'मैं']\n",
            "    labels: ['आपका', 'मैं', 'अध्यक्षा', 'आदरणीय', 'जी', 'आपका', 'अध्यक्षा', 'आभार']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XMtudJAw0JxY"
      },
      "source": [
        "### 3. Tensorflow Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-vUf--do6ZuE",
        "colab": {}
      },
      "source": [
        "\n",
        "batch_size = 128\n",
        "embedding_size = 128\n",
        "skip_window = 1\n",
        "num_skips = 2\n",
        "valid_size = 16\n",
        "valid_window = 100\n",
        "valid_examples = np.array(random.sample(range(valid_window), valid_size))\n",
        "num_sampled = 64\n",
        "\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default(), tf.device('/cpu:0'):\n",
        "    train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n",
        "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
        "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
        "    \n",
        "    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
        "    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size)))\n",
        "    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
        "    \n",
        "    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n",
        "    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed,\n",
        "                                                    labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n",
        "    \n",
        "    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n",
        "    \n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
        "    normalized_embeddings = embeddings / norm\n",
        "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
        "    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BZ12I9Ry6ZuJ",
        "outputId": "176678d0-0c5b-4c06-b245-fe6a9e671c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_steps = 100001\n",
        "\n",
        "with tf.Session(graph=graph) as session:\n",
        "    tf.global_variables_initializer().run()\n",
        "    print(\"Initialized\")\n",
        "    average_loss = 0\n",
        "    \n",
        "    for step in range(num_steps):\n",
        "        batch_data, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n",
        "        feed_dict = {train_dataset:batch_data, train_labels:batch_labels}\n",
        "        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n",
        "        average_loss += l\n",
        "        \n",
        "        if step % 2000 == 0:\n",
        "            if step > 0:\n",
        "                average_loss = average_loss / 2000\n",
        "            \n",
        "            print(\"Average loss at step %d: %f\" % (step, average_loss))\n",
        "            average_loss = 0\n",
        "        \n",
        "        if step % 10000 == 0:\n",
        "            sim = similarity.eval()\n",
        "            for i in range(valid_size):\n",
        "                valid_word = reverse_dictionary[valid_examples[i]]\n",
        "                top_k = 8\n",
        "                nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
        "                log = 'Nearest to %s:' % valid_word\n",
        "                for k in range(top_k):\n",
        "                    close_word = reverse_dictionary[nearest[k]]\n",
        "                    log = '%s %s,' % (log, close_word)\n",
        "                print(log)\n",
        "    final_embeddings = normalized_embeddings.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized\n",
            "Average loss at step 0: 7.820859\n",
            "Nearest to नहीं: अवनत, बढ़ाती, ताने, डालेंगी, मददें, भावविभोर, मुस्लिमों, मल्टीडॉयमेंशनल,\n",
            "Nearest to आज: वजहें, ग्रांटेड, स्थूल, कुंपा, अच्छीअच्छी, सहे, जलती, ओझल,\n",
            "Nearest to थे: आकड़ें, टेरीटरी, करोड़वां, कूकर, पहलू, छोटी, होंगेचंद्रशेखर, बेस्ड,\n",
            "Nearest to हम: घुसपैठिएं, हड़़प, आसकता, अपने, बिसात, ढकोसला, कातने, सिलेक्ट,\n",
            "Nearest to हूं: पिलाएं, जाएंगी, कोनों, हूंइतना, मंगवाएं, शिला, पतिपत्नी, पैदा,\n",
            "Nearest to जो: दसबारह, सॉफ्ट, देवनारायण, पच्चतहर, मोहमदी, चंद्रकुमार, पूछो, हरसिमरत,\n",
            "Nearest to मैंने: डीक्रिमिनलाइज, वादियों, बरेली, पीढी, बधुतबहुत, एडवर्डटाइजिंग, गुरु, वाना,\n",
            "Nearest to हुआ: वाली, स्पेलिंग, फाइनेन्स, रावशरद, बैंलेस, पित, सुफल, मुफ्ती,\n",
            "Nearest to तक: ख्वाब, महासत्ता, बमुश्किल, एकजुट, गोडबोले, चरखा, एमएसएमई, बॉयोटेक्नोलॉजी,\n",
            "Nearest to : मोहम्मद, लोकअदालत, अनूठा, आयुष, साबरमति, सेहत, लाके, वला,\n",
            "Nearest to करोड़: खडे, बंकर, कटोराआज, इन्वाइट, चालाकियां, लोहड़ी, बारीपदा, केमिकल,\n",
            "Nearest to जा: हैप्रत्येक, सर्वँ, पकाने, ईरानी, रेलमंत्री, अग्रमा, फैजाबाद, पीट,\n",
            "Nearest to है: रहुंगा, शादीब्याह, सीएचसी, सेपूबड़ी, संपादकीय, दीवारों, दिवानों, शुद्धिकरण,\n",
            "Nearest to होगा: पहुंचोगे, सोलिड, वनस्पतियों, इम्तिहान, वातावर्ण, सुनेगा, मगर, बनाइ,\n",
            "Nearest to दुनिया: स्टेप्स, हैआपको, बल्दिया, केवडि़या, एकेडमी, लगाएगा, मचा, खिलखिलाट,\n",
            "Nearest to बहुत: हूजी, विश्वे, उसस, जनकल्याण, आश्वास्त, दार्शनिक, आहे, बांग्लादेश,\n",
            "Average loss at step 2000: 4.252111\n",
            "Average loss at step 4000: 3.675831\n",
            "Average loss at step 6000: 3.525094\n",
            "Average loss at step 8000: 3.424422\n",
            "Average loss at step 10000: 3.371488\n",
            "Nearest to नहीं: बढ़ाती, क्या, वो, अलंकार, प्रसूता, गौड़ा, न, स्वीकर,\n",
            "Nearest to आज: जब, अब, मैं, इंसानियत, लेकिन, झाडूपोछा, वजहें, लेखक,\n",
            "Nearest to थे: हैं, होंगे, खिसकती, हुए, हल्कीहल्की, फले, ग्रामोदयसे, गईं,\n",
            "Nearest to हम: आप, मैं, वैक्सीनेशन, पीटने, एप्लीकेशन, अनुयायी, हमने, अंधेरी,\n",
            "Nearest to हूं: हूँ, है, था, मैं, मनायाकार्यकर्ता, बताएं, पकड़कर, रहेगा,\n",
            "Nearest to जो: क्या, भोलेपन, ये, तो, यह, सारे, वो, जनसमूह,\n",
            "Nearest to मैंने: हमने, मैं, डीक्रिमिनलाइज, टेक्निशियन, शायद, भाइयों, सुरक्षासबको, व्यायाम,\n",
            "Nearest to हुआ: किया, होता, पले, होगा, सलामती, वचनपत्र, यादों, हैकितने,\n",
            "Nearest to तक: जेएएम, तीन, सुनील, में, रहमान, कम्युनिटिज, एकचूलि, दिनभर,\n",
            "Nearest to : मोहम्मद, अनूठा, सेहत, लोकअदालत, जीबताइएलखन, साबरमति, लाके, वला,\n",
            "Nearest to करोड़: लाख, खडे, महाराणा, बांस, दशहरा, पाणिनी, इन्वाइट, दूसराभारत,\n",
            "Nearest to जा: रेलमंत्री, हैप्रत्येक, लड़, पकाने, बाउंडरी, एक्टीविटीस्, चित्तौड़, बढ़ाऐंगे,\n",
            "Nearest to है: था, हूं, थी, होगा, हूँ, हैं, हो, चाहिए,\n",
            "Nearest to होगा: था, है, चाहिए, वातावर्ण, जाके, पहुंचोगे, हुआ, इम्तिहान,\n",
            "Nearest to दुनिया: एक्सप्रेस, पालनेपोसने, दिशा, गांव, छत, पढ़ेगी, सरहदों, विकास,\n",
            "Nearest to बहुत: इतनी, आशियाना, आश्वास्त, बड़ें, इतना, पड, पॉपूलर, भिन्नभिन्न,\n",
            "Average loss at step 12000: 3.307481\n",
            "Average loss at step 14000: 3.291098\n",
            "Average loss at step 16000: 3.270516\n",
            "Average loss at step 18000: 3.214530\n",
            "Average loss at step 20000: 3.216567\n",
            "Nearest to नहीं: बढ़ाती, कैसे, प्रसूता, हैटूटीफूटी, न, अलंकार, डरी, अधीर,\n",
            "Nearest to आज: जब, अब, कल, अभी, लेकिन, तब, मैं, पहले,\n",
            "Nearest to थे: हैं, होंगे, हुए, हों, परिस्थ्िातियों, तीसपैंतीस, परत, गौतम,\n",
            "Nearest to हम: आप, हमें, हमने, स्वार्थियों, बढ़ाता, मैं, पीटने, अंधेरी,\n",
            "Nearest to हूं: हूँ, था, है, उठाएगें, बताएं, होगा, विटोरा, अव्यवस्थाएं,\n",
            "Nearest to जो: अगर, ये, जब, यह, कड़क, भोलेपन, कांपता, अरेस्ट,\n",
            "Nearest to मैंने: हमने, उन्होंने, मैं, सुरक्षासबको, आपने, डीक्रिमिनलाइज, शायद, पुरूवंत,\n",
            "Nearest to हुआ: होता, होगा, किया, पले, करेंगे, होल्ड, हैकितने, यादों,\n",
            "Nearest to तक: गयाऔर, जनभावनाओं, एकरूप, सुनील, प्रशासनिक, ट्राइ, परगना, जेएएम,\n",
            "Nearest to : मोहम्मद, अनूठा, लोकअदालत, लीजिए, साबरमति, सेहत, लाके, जीबताइएलखन,\n",
            "Nearest to करोड़: लाख, हजार, करोड़, खडे, महाराणा, बांस, हागरी, दूसराभारत,\n",
            "Nearest to जा: रेलमंत्री, लड़, हैप्रत्येक, चित्तौड़, पीट, एक्टीविटीस्, जमा, वीरांगनाओं,\n",
            "Nearest to है: था, हूं, होगा, थी, हैं, हूँ, बिताकरके, स्थगितता,\n",
            "Nearest to होगा: था, है, चाहिए, हुआ, करेंगे, सुनिशचित, होता, आएगी,\n",
            "Nearest to दुनिया: देश, हिन्दुस्तान, एक्सप्रेस, पालनेपोसने, छत, पढ़ेगी, सरहदों, केवडि़या,\n",
            "Nearest to बहुत: कितना, इतनी, इतना, आश्वास्त, सबसे, बड़ें, उपयोगकरते, कितनी,\n",
            "Average loss at step 22000: 3.196040\n",
            "Average loss at step 24000: 3.174124\n",
            "Average loss at step 26000: 0.933904\n",
            "Average loss at step 28000: 0.000002\n",
            "Average loss at step 30000: 0.000001\n",
            "Nearest to नहीं: न, कैसे, बढ़ाती, क्या, प्रसूता, सुकाफाको, ट्रिपलटी, अधीर,\n",
            "Nearest to आज: अब, जब, तब, कल, लेकिन, अभी, मैं, एलनेरू,\n",
            "Nearest to थे: हैं, होंगे, हों, तीसपैंतीस, हुए, थी, चाहिए, पेशेवरनिराशवादी,\n",
            "Nearest to हम: आप, हमने, स्वार्थियों, हमें, मैं, अनुयायी, खेतीबाडी, उन्होंने,\n",
            "Nearest to हूं: हूँ, था, है, होगा, उठाएगें, विटोरा, जाएंगेकर्जमाफी, इमरान,\n",
            "Nearest to जो: वो, ये, महत्वपूर्णसवाल, धरम, जितने, जब, भोलेपन, जिनको,\n",
            "Nearest to मैंने: हमने, उन्होंने, मैं, आपने, सुरक्षासबको, पुरूवंत, एमसीएमपी, जिन्होंोने,\n",
            "Nearest to हुआ: होता, किया, होगा, रहता, यूनिफाइड, वचनपत्र, आता, रहा,\n",
            "Nearest to तक: सुनील, साय, खिड़की, जेएएम, बिहारकेरलकर्नाटकओडिशा, जनभावनाओं, रहमान, गयाऔर,\n",
            "Nearest to : मोहम्मद, अनूठा, सेहत, लोकअदालत, धन्यवाद, लाके, जीबताइएलखन, साबरमति,\n",
            "Nearest to करोड़: लाख, करोड़, हजार, खडे, जनन, पाणिनी, दशहरा, महाराणा,\n",
            "Nearest to जा: लड़, रेलमंत्री, पीट, खोज, हैप्रत्येक, जाता, वीरांगनाओं, बाउंडरी,\n",
            "Nearest to है: था, थी, हूं, होगा, हूँ, हैं, थीं, बिताकरके,\n",
            "Nearest to होगा: था, है, करेंगे, होता, चाहिए, हुआ, ईसाइयों, हूं,\n",
            "Nearest to दुनिया: देश, हिन्दुस्तान, विश्व, पालनेपोसने, बिहार, परिपेक्ष्य, कमसा, तानाशाही,\n",
            "Nearest to बहुत: कितना, इतना, सबसे, इतनी, बहुतबहुत, कितनी, बड़ें, आश्वास्त,\n",
            "Average loss at step 32000: 0.000001\n",
            "Average loss at step 34000: 0.000001\n",
            "Average loss at step 36000: 0.000001\n",
            "Average loss at step 38000: 0.000000\n",
            "Average loss at step 40000: 0.000000\n",
            "Nearest to नहीं: न, कैसे, बढ़ाती, क्या, प्रसूता, सुकाफाको, ट्रिपलटी, अधीर,\n",
            "Nearest to आज: अब, जब, तब, कल, लेकिन, अभी, मैं, एलनेरू,\n",
            "Nearest to थे: हैं, होंगे, हों, तीसपैंतीस, हुए, थी, चाहिए, पेशेवरनिराशवादी,\n",
            "Nearest to हम: आप, हमने, स्वार्थियों, हमें, मैं, अनुयायी, खेतीबाडी, उन्होंने,\n",
            "Nearest to हूं: हूँ, था, है, होगा, उठाएगें, विटोरा, जाएंगेकर्जमाफी, इमरान,\n",
            "Nearest to जो: वो, ये, महत्वपूर्णसवाल, धरम, जितने, जब, भोलेपन, जिनको,\n",
            "Nearest to मैंने: हमने, उन्होंने, मैं, आपने, सुरक्षासबको, पुरूवंत, एमसीएमपी, जिन्होंोने,\n",
            "Nearest to हुआ: होता, किया, होगा, रहता, यूनिफाइड, वचनपत्र, आता, रहा,\n",
            "Nearest to तक: सुनील, साय, खिड़की, जेएएम, बिहारकेरलकर्नाटकओडिशा, जनभावनाओं, रहमान, गयाऔर,\n",
            "Nearest to : मोहम्मद, अनूठा, सेहत, धन्यवाद, लोकअदालत, लाके, जीबताइएलखन, साबरमति,\n",
            "Nearest to करोड़: लाख, करोड़, हजार, खडे, जनन, पाणिनी, दशहरा, महाराणा,\n",
            "Nearest to जा: लड़, रेलमंत्री, पीट, खोज, हैप्रत्येक, जाता, वीरांगनाओं, बाउंडरी,\n",
            "Nearest to है: था, थी, हूं, होगा, हूँ, हैं, थीं, बिताकरके,\n",
            "Nearest to होगा: था, है, करेंगे, होता, चाहिए, हुआ, ईसाइयों, हूं,\n",
            "Nearest to दुनिया: देश, हिन्दुस्तान, विश्व, पालनेपोसने, बिहार, परिपेक्ष्य, कमसा, तानाशाही,\n",
            "Nearest to बहुत: कितना, इतना, सबसे, इतनी, बहुतबहुत, कितनी, बड़ें, आश्वास्त,\n",
            "Average loss at step 42000: 0.000000\n",
            "Average loss at step 44000: 0.000000\n",
            "Average loss at step 46000: 0.000000\n",
            "Average loss at step 48000: 0.000000\n",
            "Average loss at step 50000: 0.000000\n",
            "Nearest to नहीं: न, कैसे, बढ़ाती, क्या, प्रसूता, सुकाफाको, ट्रिपलटी, अधीर,\n",
            "Nearest to आज: अब, जब, तब, कल, लेकिन, अभी, मैं, एलनेरू,\n",
            "Nearest to थे: हैं, होंगे, हों, तीसपैंतीस, हुए, थी, चाहिए, पेशेवरनिराशवादी,\n",
            "Nearest to हम: आप, हमने, स्वार्थियों, हमें, मैं, अनुयायी, खेतीबाडी, उन्होंने,\n",
            "Nearest to हूं: हूँ, था, है, होगा, उठाएगें, विटोरा, जाएंगेकर्जमाफी, इमरान,\n",
            "Nearest to जो: वो, ये, महत्वपूर्णसवाल, धरम, जितने, जब, भोलेपन, जिनको,\n",
            "Nearest to मैंने: हमने, उन्होंने, मैं, आपने, सुरक्षासबको, पुरूवंत, एमसीएमपी, जिन्होंोने,\n",
            "Nearest to हुआ: होता, किया, होगा, रहता, यूनिफाइड, वचनपत्र, आता, रहा,\n",
            "Nearest to तक: सुनील, साय, खिड़की, जेएएम, बिहारकेरलकर्नाटकओडिशा, जनभावनाओं, रहमान, गयाऔर,\n",
            "Nearest to : मोहम्मद, अनूठा, सेहत, धन्यवाद, लोकअदालत, लाके, जीबताइएलखन, साबरमति,\n",
            "Nearest to करोड़: लाख, करोड़, हजार, खडे, जनन, पाणिनी, दशहरा, महाराणा,\n",
            "Nearest to जा: लड़, रेलमंत्री, पीट, खोज, हैप्रत्येक, जाता, वीरांगनाओं, बाउंडरी,\n",
            "Nearest to है: था, थी, हूं, होगा, हूँ, हैं, थीं, बिताकरके,\n",
            "Nearest to होगा: था, है, करेंगे, होता, चाहिए, हुआ, ईसाइयों, हूं,\n",
            "Nearest to दुनिया: देश, हिन्दुस्तान, विश्व, पालनेपोसने, बिहार, परिपेक्ष्य, कमसा, तानाशाही,\n",
            "Nearest to बहुत: कितना, इतना, सबसे, इतनी, बहुतबहुत, कितनी, बड़ें, आश्वास्त,\n",
            "Average loss at step 52000: 0.000000\n",
            "Average loss at step 54000: 0.000000\n",
            "Average loss at step 56000: 0.000000\n",
            "Average loss at step 58000: 0.000000\n",
            "Average loss at step 60000: 0.000000\n",
            "Nearest to नहीं: न, कैसे, बढ़ाती, क्या, प्रसूता, सुकाफाको, ट्रिपलटी, अधीर,\n",
            "Nearest to आज: अब, जब, तब, कल, लेकिन, अभी, मैं, एलनेरू,\n",
            "Nearest to थे: हैं, होंगे, हों, तीसपैंतीस, हुए, थी, चाहिए, पेशेवरनिराशवादी,\n",
            "Nearest to हम: आप, हमने, स्वार्थियों, हमें, मैं, अनुयायी, खेतीबाडी, उन्होंने,\n",
            "Nearest to हूं: हूँ, था, है, होगा, उठाएगें, विटोरा, जाएंगेकर्जमाफी, इमरान,\n",
            "Nearest to जो: वो, ये, महत्वपूर्णसवाल, धरम, जितने, जब, भोलेपन, जिनको,\n",
            "Nearest to मैंने: हमने, उन्होंने, मैं, आपने, सुरक्षासबको, पुरूवंत, एमसीएमपी, जिन्होंोने,\n",
            "Nearest to हुआ: होता, किया, होगा, रहता, यूनिफाइड, वचनपत्र, आता, रहा,\n",
            "Nearest to तक: सुनील, साय, खिड़की, जेएएम, बिहारकेरलकर्नाटकओडिशा, जनभावनाओं, रहमान, गयाऔर,\n",
            "Nearest to : मोहम्मद, अनूठा, सेहत, धन्यवाद, लोकअदालत, लाके, जीबताइएलखन, साबरमति,\n",
            "Nearest to करोड़: लाख, करोड़, हजार, खडे, जनन, पाणिनी, दशहरा, महाराणा,\n",
            "Nearest to जा: लड़, रेलमंत्री, पीट, खोज, हैप्रत्येक, जाता, वीरांगनाओं, बाउंडरी,\n",
            "Nearest to है: था, थी, हूं, होगा, हूँ, हैं, थीं, बिताकरके,\n",
            "Nearest to होगा: था, है, करेंगे, होता, चाहिए, हुआ, ईसाइयों, हूं,\n",
            "Nearest to दुनिया: देश, हिन्दुस्तान, विश्व, पालनेपोसने, बिहार, परिपेक्ष्य, कमसा, तानाशाही,\n",
            "Nearest to बहुत: कितना, इतना, सबसे, इतनी, बहुतबहुत, कितनी, बड़ें, आश्वास्त,\n",
            "Average loss at step 62000: 0.000000\n",
            "Average loss at step 64000: 0.000000\n",
            "Average loss at step 66000: 0.000000\n",
            "Average loss at step 68000: 0.000000\n",
            "Average loss at step 70000: 0.000000\n",
            "Nearest to नहीं: न, कैसे, बढ़ाती, क्या, प्रसूता, सुकाफाको, ट्रिपलटी, अधीर,\n",
            "Nearest to आज: अब, जब, तब, कल, लेकिन, अभी, मैं, एलनेरू,\n",
            "Nearest to थे: हैं, होंगे, हों, तीसपैंतीस, हुए, थी, चाहिए, पेशेवरनिराशवादी,\n",
            "Nearest to हम: आप, हमने, स्वार्थियों, हमें, मैं, अनुयायी, खेतीबाडी, उन्होंने,\n",
            "Nearest to हूं: हूँ, था, है, होगा, उठाएगें, विटोरा, जाएंगेकर्जमाफी, इमरान,\n",
            "Nearest to जो: वो, ये, महत्वपूर्णसवाल, धरम, जितने, जब, भोलेपन, जिनको,\n",
            "Nearest to मैंने: हमने, उन्होंने, मैं, आपने, सुरक्षासबको, पुरूवंत, एमसीएमपी, जिन्होंोने,\n",
            "Nearest to हुआ: होता, किया, होगा, रहता, यूनिफाइड, वचनपत्र, आता, रहा,\n",
            "Nearest to तक: सुनील, साय, खिड़की, जेएएम, बिहारकेरलकर्नाटकओडिशा, जनभावनाओं, रहमान, गयाऔर,\n",
            "Nearest to : मोहम्मद, अनूठा, सेहत, धन्यवाद, लोकअदालत, लाके, जीबताइएलखन, साबरमति,\n",
            "Nearest to करोड़: लाख, करोड़, हजार, खडे, जनन, पाणिनी, दशहरा, महाराणा,\n",
            "Nearest to जा: लड़, रेलमंत्री, पीट, खोज, हैप्रत्येक, जाता, वीरांगनाओं, बाउंडरी,\n",
            "Nearest to है: था, थी, हूं, होगा, हूँ, हैं, थीं, बिताकरके,\n",
            "Nearest to होगा: था, है, करेंगे, होता, चाहिए, हुआ, ईसाइयों, हूं,\n",
            "Nearest to दुनिया: देश, हिन्दुस्तान, विश्व, पालनेपोसने, बिहार, परिपेक्ष्य, कमसा, तानाशाही,\n",
            "Nearest to बहुत: कितना, इतना, सबसे, इतनी, बहुतबहुत, कितनी, बड़ें, आश्वास्त,\n",
            "Average loss at step 72000: 0.000000\n",
            "Average loss at step 74000: 0.000000\n",
            "Average loss at step 76000: 0.000000\n",
            "Average loss at step 78000: 0.000000\n",
            "Average loss at step 80000: 0.000000\n",
            "Nearest to नहीं: न, कैसे, बढ़ाती, क्या, प्रसूता, सुकाफाको, ट्रिपलटी, अधीर,\n",
            "Nearest to आज: अब, जब, तब, कल, लेकिन, अभी, मैं, एलनेरू,\n",
            "Nearest to थे: हैं, होंगे, हों, तीसपैंतीस, हुए, थी, चाहिए, पेशेवरनिराशवादी,\n",
            "Nearest to हम: आप, हमने, स्वार्थियों, हमें, मैं, अनुयायी, खेतीबाडी, उन्होंने,\n",
            "Nearest to हूं: हूँ, था, है, होगा, उठाएगें, विटोरा, जाएंगेकर्जमाफी, इमरान,\n",
            "Nearest to जो: वो, ये, महत्वपूर्णसवाल, धरम, जितने, जब, भोलेपन, जिनको,\n",
            "Nearest to मैंने: हमने, उन्होंने, मैं, आपने, सुरक्षासबको, पुरूवंत, एमसीएमपी, जिन्होंोने,\n",
            "Nearest to हुआ: होता, किया, होगा, रहता, यूनिफाइड, वचनपत्र, आता, रहा,\n",
            "Nearest to तक: सुनील, साय, खिड़की, जेएएम, बिहारकेरलकर्नाटकओडिशा, जनभावनाओं, रहमान, गयाऔर,\n",
            "Nearest to : मोहम्मद, अनूठा, सेहत, धन्यवाद, लोकअदालत, लाके, जीबताइएलखन, साबरमति,\n",
            "Nearest to करोड़: लाख, करोड़, हजार, खडे, जनन, पाणिनी, दशहरा, महाराणा,\n",
            "Nearest to जा: लड़, रेलमंत्री, पीट, खोज, हैप्रत्येक, जाता, वीरांगनाओं, बाउंडरी,\n",
            "Nearest to है: था, थी, हूं, होगा, हूँ, हैं, थीं, बिताकरके,\n",
            "Nearest to होगा: था, है, करेंगे, होता, चाहिए, हुआ, ईसाइयों, हूं,\n",
            "Nearest to दुनिया: देश, हिन्दुस्तान, विश्व, पालनेपोसने, बिहार, परिपेक्ष्य, कमसा, तानाशाही,\n",
            "Nearest to बहुत: कितना, इतना, सबसे, इतनी, बहुतबहुत, कितनी, बड़ें, आश्वास्त,\n",
            "Average loss at step 82000: 0.000000\n",
            "Average loss at step 84000: 0.000000\n",
            "Average loss at step 86000: 0.000000\n",
            "Average loss at step 88000: 0.000000\n",
            "Average loss at step 90000: 0.000000\n",
            "Nearest to नहीं: न, कैसे, बढ़ाती, क्या, प्रसूता, सुकाफाको, ट्रिपलटी, अधीर,\n",
            "Nearest to आज: अब, जब, तब, कल, लेकिन, अभी, मैं, एलनेरू,\n",
            "Nearest to थे: हैं, होंगे, हों, तीसपैंतीस, हुए, थी, चाहिए, पेशेवरनिराशवादी,\n",
            "Nearest to हम: आप, हमने, स्वार्थियों, हमें, मैं, अनुयायी, खेतीबाडी, उन्होंने,\n",
            "Nearest to हूं: हूँ, था, है, होगा, उठाएगें, विटोरा, जाएंगेकर्जमाफी, इमरान,\n",
            "Nearest to जो: वो, ये, महत्वपूर्णसवाल, धरम, जितने, जब, भोलेपन, जिनको,\n",
            "Nearest to मैंने: हमने, उन्होंने, मैं, आपने, सुरक्षासबको, पुरूवंत, एमसीएमपी, जिन्होंोने,\n",
            "Nearest to हुआ: होता, किया, होगा, रहता, यूनिफाइड, वचनपत्र, आता, रहा,\n",
            "Nearest to तक: सुनील, साय, खिड़की, जेएएम, बिहारकेरलकर्नाटकओडिशा, जनभावनाओं, रहमान, गयाऔर,\n",
            "Nearest to : मोहम्मद, अनूठा, सेहत, धन्यवाद, लोकअदालत, लाके, जीबताइएलखन, साबरमति,\n",
            "Nearest to करोड़: लाख, करोड़, हजार, खडे, जनन, पाणिनी, दशहरा, महाराणा,\n",
            "Nearest to जा: लड़, रेलमंत्री, पीट, खोज, हैप्रत्येक, जाता, वीरांगनाओं, बाउंडरी,\n",
            "Nearest to है: था, थी, हूं, होगा, हूँ, हैं, थीं, बिताकरके,\n",
            "Nearest to होगा: था, है, करेंगे, होता, चाहिए, हुआ, ईसाइयों, हूं,\n",
            "Nearest to दुनिया: देश, हिन्दुस्तान, विश्व, पालनेपोसने, बिहार, परिपेक्ष्य, कमसा, तानाशाही,\n",
            "Nearest to बहुत: कितना, इतना, सबसे, इतनी, बहुतबहुत, कितनी, बड़ें, आश्वास्त,\n",
            "Average loss at step 92000: 0.000000\n",
            "Average loss at step 94000: 0.000000\n",
            "Average loss at step 96000: 0.000000\n",
            "Average loss at step 98000: 0.000000\n",
            "Average loss at step 100000: 1.213908\n",
            "Nearest to नहीं: न, बढ़ाती, प्रसूता, क्या, कैसे, अधीर, हैटूटीफूटी, बढ़बढ़,\n",
            "Nearest to आज: अब, जब, कल, तब, अभी, लेकिन, एलनेरू, क्योंकि,\n",
            "Nearest to थे: हैं, होंगे, हों, हुए, तीसपैंतीस, फले, रचने, काम्बेट,\n",
            "Nearest to हम: आप, मैं, हमने, स्वार्थियों, हमें, अनुयायी, व्यवस्थित, वो,\n",
            "Nearest to हूं: हूँ, है, था, होगा, उठाएगें, विटोरा, लगाएइये, जामवाल,\n",
            "Nearest to जो: वो, क्या, धरम, अरेस्ट, महत्वपूर्णसवाल, ये, यह, पायरेसी,\n",
            "Nearest to मैंने: हमने, उन्होंने, मैं, आपने, सुरक्षासबको, पुरूवंत, एमसीएमपी, मिथ्याकारक,\n",
            "Nearest to हुआ: होता, किया, होगा, रहता, ज़रूर, हैकितने, वचनपत्र, आता,\n",
            "Nearest to तक: सुनील, साय, बिहारकेरलकर्नाटकओडिशा, गयाऔर, रहमान, जेएएम, एकरूप, गगनचुंबी,\n",
            "Nearest to : मोहम्मद, अनूठा, लोकअदालत, सेहत, जीबताइएलखन, लाके, साबरमति, वला,\n",
            "Nearest to करोड़: लाख, हजार, करोड़, खडे, दशहरा, जनन, महाराणा, पाणिनी,\n",
            "Nearest to जा: लड़, रेलमंत्री, हैप्रत्येक, पीट, खोज, बाउंडरी, जाता, गृहों,\n",
            "Nearest to है: था, हूं, थी, होगा, हूँ, थीं, होगी, हो,\n",
            "Nearest to होगा: था, है, करेंगे, चाहिए, होता, हूं, हुआ, करेगा,\n",
            "Nearest to दुनिया: विश्व, देश, हिन्दुस्तान, तानाशाही, पालनेपोसने, एक्सप्रेस, स्क्रीनिंग, बिहार,\n",
            "Nearest to बहुत: कितना, इतना, सबसे, इतनी, कितनी, बहुतबहुत, आश्वास्त, काफी,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vs8oz2nE0Nn2"
      },
      "source": [
        "### 4. Output Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dirXRgSP6ZuN",
        "colab": {}
      },
      "source": [
        "num_points = 400\n",
        "\n",
        "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
        "two_d_embeddings = tsne.fit_transform(final_embeddings[1:num_points+1, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vJtDFSwb6ZuR",
        "colab": {}
      },
      "source": [
        "def plot(embeddings, labels):\n",
        "    assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n",
        "    pylab.figure(figsize=(15, 15))\n",
        "    for i, label in enumerate(labels):\n",
        "        x, y = embeddings[i, :]\n",
        "        pylab.scatter(x, y)\n",
        "        pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom', fontproperties=hindi_font)\n",
        "    pylab.show()\n",
        "\n",
        "words = [reverse_dictionary[i] for i in range(1, num_points+1)]\n",
        "plot(two_d_embeddings, words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q_v8N_en6ZuV",
        "colab": {}
      },
      "source": [
        "final_data = {\n",
        "    'embeddings': final_embeddings,\n",
        "    'dictionary': dictionary,\n",
        "    'reverse_dictionary': reverse_dictionary\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n0Ap7wbJ6ZuY",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(root, 'embeddings_sg.hi'), 'wb') as f:\n",
        "    pickle.dump(file=f, obj=final_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WpIJZg116Zub",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}